{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demo for Xray Detection",
   "id": "e63b408b54caa00d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Введение\n",
    "\n",
    "Для решения задачи, связанной с обнаружением координат аномалий и их классификацией, я применил несколько различных подходов и технологий:\n",
    "\n",
    "1. Библиотека MMDetection с использованием двух моделей:\n",
    "   - Базовая модель RTMDet\n",
    "   - Более сложная модель на основе Cascade RFP R50\n",
    "\n",
    "2. Библиотека Ultralytics с использованием моделей YOLOv8:\n",
    "   - YOLOv8m (medium)\n",
    "   - YOLOv8x (extra large)\n",
    "\n",
    "3. Библиотека Ultralytics с использованием модели YOLOv5:\n",
    "   - YOLOv5x (extra large)\n",
    "\n",
    "Каждый из этих подходов был выбран для оптимизации процесса обнаружения и классификации аномалий, учитывая их различные сильные стороны и особенности."
   ],
   "id": "d23696293f3cf804"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Предобработка данных\n",
    "\n",
    "Учитывая ограниченный объем оригинального датасета, было принято решение оптимизировать использование имеющихся данных. Процесс подготовки данных включал следующие этапы:\n",
    "\n",
    "1. Разделение датасета:\n",
    "   - Равномерное разделение данных на тренировочную и тестовую выборки с учетом баланса классов.\n",
    "   - Тестовая выборка: около 250 экземпляров.\n",
    "   - Исходная тренировочная выборка: около 650 экземпляров.\n",
    "\n",
    "2. Аугментация данных:\n",
    "   - Применение методов аугментации для искусственного увеличения объема тренировочной выборки.\n",
    "   - Увеличение тренировочного набора примерно в 5 раз.\n",
    "   - Итоговый объем тренировочной выборки: 650 исходных + 3500 аугментированных экземпляров.\n",
    "\n",
    "3. Результат:\n",
    "   - Тестовая выборка: ~250 экземпляров.\n",
    "   - Расширенная тренировочная выборка: ~4150 экземпляров (650 оригинальных + 3500 аугментированных).\n",
    "\n",
    "Код для реализации аугментации будет представлен в следующих разделах."
   ],
   "id": "566538f802889df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.HorizontalFlip(p=0.2),\n",
    "    A.RandomRotate90(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "    A.Blur(p=0.2),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.Resize(1024, 1024)\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "\n",
    "def load_image_and_labels(image_path, label_path):\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "\n",
    "    # Load labels\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            bboxes.append([x_center, y_center, width, height])\n",
    "            class_labels.append(int(class_id))\n",
    "\n",
    "    return image, bboxes, class_labels\n",
    "\n",
    "\n",
    "def save_augmented_data(augmented_image, augmented_bboxes, augmented_labels, output_image_path, output_label_path):\n",
    "    augmented_image_pil = Image.fromarray(augmented_image)\n",
    "    augmented_image_pil.save(output_image_path)\n",
    "\n",
    "    with open(output_label_path, 'w') as file:\n",
    "        for bbox, label in zip(augmented_bboxes, augmented_labels):\n",
    "            bbox_str = ' '.join(map(str, bbox))\n",
    "            file.write(f\"{label} {bbox_str}\\n\")\n",
    "\n",
    "\n",
    "def augment_and_save(image_path, label_path, output_image_dir, output_label_dir, num_augmentations=5):\n",
    "    image, bboxes, class_labels = load_image_and_labels(image_path, label_path)\n",
    "    base_name = os.path.basename(image_path)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        augmented = augmentation_pipeline(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_bboxes = augmented['bboxes']\n",
    "        augmented_labels = augmented['class_labels']\n",
    "\n",
    "        output_image_path = os.path.join(output_image_dir, f\"{name}_aug_{i}{ext}\")\n",
    "        output_label_path = os.path.join(output_label_dir, f\"{name}_aug_{i}.txt\")\n",
    "\n",
    "        save_augmented_data(augmented_image, augmented_bboxes, augmented_labels, output_image_path, output_label_path)\n",
    "\n",
    "\n",
    "train_images_dir = \"/data/yolo_dataset/train/images\"\n",
    "train_labels_dir = \"/data/yolo_dataset/train/labels\"\n",
    "augmented_images_dir = \"/data/yolo_dataset/augmented/images\"\n",
    "augmented_labels_dir = \"/data/yolo_dataset/augmented/labels\"\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "os.makedirs(augmented_labels_dir, exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for image_file in os.listdir(train_images_dir):\n",
    "    if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(train_images_dir, image_file)\n",
    "        label_path = os.path.join(train_labels_dir,\n",
    "                                  image_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "        augment_and_save(image_path, label_path, augmented_images_dir, augmented_labels_dir, num_augmentations=5)\n",
    "        print(image_path, index)\n",
    "        index+=1"
   ],
   "id": "cc0abf841aac0c75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Проверка гипотез и тренировка модели на основе технологии mmdetection\n",
    "\n",
    "Базовая модель на основе RTMDet была использована чтобы выроботать процесс тренировки на основе технологии mmdetection. Затем после проверки гипотез и правильного выстроенного пайплайна я решил попробовать использовать каскадную модель на основе Cascade RFP R50. Базовая конфигурация модели была использована, как показано ниже:\n",
    "\n",
    "\n",
    "Эта структура будет использована для multi class detection и single class detection. Также для проверки обучаемости я добавлял и убавлял ту часть данных, которая была сгенерирована.\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "f3ddccdfff25f4e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T08:03:01.174378Z",
     "start_time": "2024-06-27T08:03:01.167639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = dict(\n",
    "    roi_head=dict(\n",
    "        bbox_head=[\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=8,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=8,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=8,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
    "        ]),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_across_levels=False,\n",
    "            nms_pre=1000,\n",
    "            nms_post=1000,\n",
    "            max_num=1000,\n",
    "            nms_thr=0.7,\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            score_thr=0.001,\n",
    "            nms=dict(type='nms', iou_threshold=0.5),\n",
    "            max_per_img=100,\n",
    "            mask_thr_binary=0.5)))"
   ],
   "id": "c1c10d51c5661bc1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Результаты при использовании Multiple Detection на основе каскадной модели:\n",
    "```\n",
    "Average Precision (AP):\n",
    "- AP@[IoU=0.50:0.95 | area=all | maxDets=100] = 0.061\n",
    "- AP@[IoU=0.50 | area=all | maxDets=1000] = 0.117\n",
    "- AP@[IoU=0.75 | area=all | maxDets=1000] = 0.060\n",
    "- AP@[IoU=0.50:0.95 | area=small | maxDets=1000] = 0.000\n",
    "- AP@[IoU=0.50:0.95 | area=medium | maxDets=1000] = 0.012\n",
    "- AP@[IoU=0.50:0.95 | area=large | maxDets=1000] = 0.081\n",
    "\n",
    "Average Recall (AR):\n",
    "- AR@[IoU=0.50:0.95 | area=all | maxDets=100] = 0.243\n",
    "- AR@[IoU=0.50:0.95 | area=all | maxDets=300] = 0.243\n",
    "- AR@[IoU=0.50:0.95 | area=all | maxDets=1000] = 0.243\n",
    "- AR@[IoU=0.50:0.95 | area=small | maxDets=1000] = 0.000\n",
    "- AR@[IoU=0.50:0.95 | area=medium | maxDets=1000] = 0.081\n",
    "- AR@[IoU=0.50:0.95 | area=large | maxDets=1000] = 0.262\n",
    "\n",
    "COCO mAP:\n",
    "bbox_mAP: 0.0610, bbox_mAP_50: 0.1170, bbox_mAP_75: 0.0600\n",
    "bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0120, bbox_mAP_l: 0.0810\n",
    "```"
   ],
   "id": "4c6bd6ac20a1fa2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Yolov8 тренировка и проверка гипотез",
   "id": "19efaa75a8a7d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для использования библиотеки ultralytics с утилизацией модели yolov8 был сделан основной файл запуска",
   "id": "37d732a02e82adc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### конфигурация для данных выглядела таким образом\n",
    "```\n",
    "path: \"/data/new_dataset\"\n",
    "train:\n",
    "  - \"/data/new_dataset/train/images\"\n",
    "val: \"/data/new_dataset/val/images\"\n",
    "\n",
    "names:\n",
    "  0: 'Atelectasis'\n",
    "  1: 'Cardiomegaly'\n",
    "  2: 'Effusion'\n",
    "  3: 'Infiltrate'\n",
    "  4: 'Mass'\n",
    "  5: 'Nodule'\n",
    "  6: 'Pneumonia'\n",
    "  7: 'Pneumothorax'\n",
    "```\n"
   ],
   "id": "c3e340a0d4998670"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:03:14.008728Z",
     "start_time": "2024-06-27T10:03:14.006378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model = YOLO('yolov8x.pt')  # Use the YOLOv8 model variant you prefer\n",
    "\n",
    "data_config = './data.yaml'\n",
    "epochs = 1000\n",
    "batch_size = 24\n",
    "image_size = 1024\n",
    "num_workers = 64\n",
    "augmentation_params = {\n",
    "    'flipud': 0.1,    # Vertical flip probability\n",
    "    'fliplr': 0.1,    # Horizontal flip probability\n",
    "    'mosaic': 0.0,    # Mosaic augmentation probability\n",
    "    'mixup': 0.0,     # MixUp augmentation probability\n",
    "    'hsv_h': 0.015,   # HSV-Hue augmentation\n",
    "    'hsv_s': 0.1,     # HSV-Saturation augmentation\n",
    "    'hsv_v': 0.1,     # HSV-Value augmentation\n",
    "    'degrees': 0.1,   # Image rotation degrees\n",
    "    'translate': 0.1, # Image translation\n",
    "    'scale': 0.1,     # Image scaling\n",
    "    'shear': 0.0,     # Image shear\n",
    "    'perspective': 0.0 # Image perspective\n",
    "}\n",
    "\n",
    "model.train(data=data_config, epochs=epochs,workers=num_workers,batch=batch_size, imgsz=image_size,\n",
    "            save_period=10,augment=True, device=\"0,1\",optimizer=\"AdamW\",project=\"/data/new_dataset/output_dir\",name=\"final_xray\",verbose=True,plots=True, save=True, **augmentation_params)\n"
   ],
   "id": "e7497a2a3cd5d1b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "После тренировки общие результаты как показаны ниже:\n",
    "\n",
    "1. mAP50-95: 0.01576 (23-я эпоха)\n",
    "2. Точность: 0.76854 (32-я эпоха)\n",
    "3. Полнота: 0.25541 (24-я эпоха)\n",
    "\n",
    "Проблемы: \n",
    "1. Нестабильность в обучении\n",
    "2. Функция потерь по классификации стала увеличиваться\n",
    "3. Переставаемая обучаемость после определенной эпохи"
   ],
   "id": "eddc5572fc766cc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Результаты\n",
    "\n",
    "1. Было протестирована также самая последняя модель yolov5, которая так же показала хуже результаты чем yolov8. Ее показатели по mAP были ниже.\n",
    "2. Искусственное увелечение датасета привело к ухудшению результатов, нежели улучшению. По этой причине в последних тренировках были использованы данные только с оригинального датасета\n",
    "3. Изменение от multiple class detection на single class detection - приводило к тому, что результаты модели наоборот ухудшались, и модель стала путаться еще быстрее.\n",
    "    - Общий mAP@0.5 (средняя точность при пороге IoU 0.5) составляет 0.092, что указывает на то, что производительность модели очень низкая для single класса\n",
    "    - Для модели по mmdetection результаты схожи, показатели mAP при 0.5 IoU - 0.1\n"
   ],
   "id": "12c194a992e0d1f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Что можно улучшить?\n",
    "1. Увеличить датасет используя остаток данных( их там около 110К ), используя авто аннотацию на основе модели, которая была протренирована на датасете VinBigData Xray. В ней присутствуют все классы указанные в этом датасете.\n",
    "2. Объединить такие классы как Mass/Nodule в один\n",
    "3. Добавить weight_decay в sampler\n",
    "4. Попробовать использовать FocalNet, так как она лучше работает при несбалансированных датасетах на основе FocalLoss\n",
    "5. Также можно попробовать использовать DETR модель, которая на данный момент является SOTA на COCO dataset"
   ],
   "id": "63ad1a7413641047"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "312461ec5b1afdb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9e6bd3317b44cba3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
